vvar<-ifelse(is.na(vvar),0.0,vvar)
# link MAPCOLORS for variable to shape object (https://gist.github.com/mbacou/5880859)
# Color classification of variable
iprob<-5
set_unique_breaks <- function(x,ip) {
chk1 <- quantile(x, probs=0:ip/ip)
chk <- unique(quantile(x, probs=0:ip/ip)) # define quartiles
# exit if the condition is met
if (length(chk1) == length(chk)) return(ip)
ip<-ip-1
Recall(x,ip) # run the function again
}
iprob <- set_unique_breaks(vvar,iprob)
nintervals[k] <- iprob
if(iprob >=2 ) {
chk1 <- quantile(vvar, probs=0:iprob/iprob)
chk <- unique(quantile(vvar, probs=0:iprob/iprob)) # define quartiles
qvars <- as.integer(cut(vvar, quantile(vvar, probs=0:iprob/iprob), include.lowest=TRUE))  # classify variable
Mcolors <- c("blue","dark green","gold","red","dark red")
Mcolors <- Mcolors[1:(length(chk1)-1)]
# http://research.stowers-institute.org/efg/R/Color/Chart/index.htm
MAPCOLORS <- Mcolors[qvars]
dmap <- data.frame(MAPID,as.character(MAPCOLORS))   # ,vvar)    # added 3-25-2017
mapvarname <- paste("MAPCOLORS",k,sep="")
colnames(dmap) <- c(commonvar,mapvarname) # ,master_map_list[k])
intervals[k,1:length(chk)] <- chk
nintervals[k] <- length(chk)-1
} else {
# setup 5 breakpoints with majority of values in a single class
brks1 <- c(min(vvar),median(vvar),max(vvar))
sub <- subset(vvar,vvar!=median(vvar))
iprob <- 3
chk1 <- quantile(sub, probs=0:iprob/iprob)
# add 5th breakpoint based on the min or max value equals the median
brks <- numeric(5)
if(median(vvar)==max(vvar)){  # add an upper class
brks[1:4] <- chk1
brks[5] <- max(vvar)
} else {   # add a lower class
brks[1] <- min(vvar)
brks[2:5] <- chk1
}
qvars <- as.integer(cut(vvar, brks, include.lowest=TRUE))  # classify variable
Mcolors <- c("blue","dark green","gold","red","dark red")
Mcolors <- Mcolors[1:(length(brks)-1)]
# http://research.stowers-institute.org/efg/R/Color/Chart/index.htm
MAPCOLORS <- Mcolors[qvars]
dmap <- data.frame(MAPID,as.character(MAPCOLORS))   # ,vvar)    # added 3-25-2017
mapvarname <- paste("MAPCOLORS",k,sep="")
colnames(dmap) <- c(commonvar,mapvarname) # ,master_map_list[k])
intervals[k,1:length(brks)] <- brks
nintervals[k] <- length(brks)-1
}
}
if(mapgo.list[k] > 0){
dmapfinal <- merge(dmapfinal,dmap,by=commonvar)
mapvarname <- paste("dmapfinal$MAPCOLORS",k," <- as.character(dmapfinal$MAPCOLORS",k,")",sep="")
eval(parse(text=mapvarname))
}
} # end variable loop
#------------------------------------------------------------#
# merge selected variables to the shape file
lineShape <- sp::merge(lineShape, dmapfinal, by.x = commonvar, by.y = commonvar)
# Create and output maps
filename <- paste(path_results,"/maps/",file_sum,"_prediction_stream_maps.pdf",sep="")
# pdf(file=filename)
# loop through each of the variables...
Mcolors <- c("blue","dark green","gold","red","dark red")
for (k in 1:length(master_map_list)) {
if(!is.na(LineShapeGeo)) {
plot(GeoLines,col=1,lwd=0.1,xlim=lon_limit,ylim=lat_limit)
}
# obtain variable settings
mapvarname <- paste("lineShape$MAPCOLORS",k,sep="")
# select the shading colors for a given mapping variable
if(!is.na(LineShapeGeo)) {
xtext <- paste("sp::plot(lineShape,col=",mapvarname,",lwd=0.8, add=TRUE)",sep="")
eval(parse(text=xtext))
} else {
xtext <- paste("sp::plot(lineShape,col=",mapvarname,",lwd=0.8)",sep="")
eval(parse(text=xtext))
}
title(master_map_list[k])
break1 <- as.character(intervals[1:nintervals[k]])
for (i in 1:nintervals[k]) {
break1[i] <- paste(round(intervals[k,i],digit=2)," TO ",round(intervals[k,i+1],digit=2),sep="")
}
nlty <-rep(1,nintervals[k])
nlwd <- rep(0.8,nintervals[k])
legend("bottomleft",break1,lty=nlty,cex=0.6,title=mapunits.list[k],
bg="grey",lwd=nlwd, col=Mcolors, bty="o")
}
}#end myplot
output$plotOne  <- renderPlot({  #set mapping input variable
myplot()
})
#activate radio button
observeEvent(input$do, {
#output$down <- downloadHandler(
if (!dir.exists(paste(path_results,"/maps/Interactive/",sep=""))){
dir.create(paste(path_results,"/maps/Interactive/",sep=""))
}
filename<- paste(path_results,"/maps/Interactive/",file_sum,"_",input$var,".pdf",sep="")
pdf(filename)
myplot()
dev.off()
showModal(modalDialog(
title = "",
"Plot save action complete"
))
})#end radio button
session$onSessionEnded(function() {
stopApp()
})
})
)
# },TRUE)#end try
#  if (class(tryIt)=="try-error"){#if an error occured
#    if(ErrorOccured=="no"){
#      ErrorOccured<-"yes"
#      cat("\n \n")
#      message(paste("AN ERROR OCCURRED IN PROCESSING shinyMap.R\n",
##                    geterrmessage(),"RUN EXECUTION TERMINATED.",sep=""))
#      if (batch_mode=="yes"){#if batch output message to log
#        cat(" \nAN ERROR OCCURRED IN PROCESSING shinyMap.R\n",
#            geterrmessage(),"RUN EXECUTION TERMINATED.",sep="")
#      }}
#    assign("ErrorOccured","yes",envir = .GlobalEnv)
#    assign("ErrorOccured","yes",envir = parent.frame())
#  }else{#if no error#
#
#    }#end if error
#
#  }#test if previous error
}
shiny::runApp(shinyMap(path_results,file_sum,path_gis,map_uncertainties,BootUncertainties,
data_names,mapping.input.list,predict.list,subdata,SelParmValues,
batch_mode,ErrorOccured))
shiny::runApp(shinyMap(path_results,file_sum,path_gis,map_uncertainties,BootUncertainties,
data_names,mapping.input.list,predict.list,subdata,SelParmValues,
batch_mode,ErrorOccured))
shiny::runApp(shinyMap(path_results,file_sum,path_gis,map_uncertainties,BootUncertainties,
data_names,mapping.input.list,predict.list,subdata,SelParmValues,
batch_mode,ErrorOccured))
data<-read.csv("D:/Table7A.csv")
data
data<-read.csv("D:/Table7A.csv")
data<-data[-c(1)]
length(which(data>90,arr.ind=TRUE))/length(which(data<=90,arr.ind=TRUE))*100
Q<-read.csv("C:/Users/lgormansanisaca/Downloads/Q_LILY.csv")
SSC<-read.csv("C:/Users/lgormansanisaca/Downloads/SSC_LILY.csv")
sapply(Q,class)
head(Q)
?as.POSIXct
Q$Time.stamp<-as.POSIXlt(Q$Time.stamp)
Q$Time.stamp<-as.POSIXct(Q$Time.stamp)
Q<-read.csv("C:/Users/lgormansanisaca/Downloads/Q_LILY.csv")
SSC<-read.csv("C:/Users/lgormansanisaca/Downloads/SSC_LILY.csv")
Q$Time.stamp<-strptime(Q$Time.stamp, "%m/%d/%Y %H:%M")
head(Q)
sapply(Q,class)
head(SSC)
SSC$DATE.TIME<-strptime(SSC$DATE.TIME, "%m/%d/%Y %H:%M")
head(SSC)
sapply(SSC, class)
data<-merge(Q,SSC, by.x=Q$Time.stamp,by.y=SSC$DATE.TIME,all.x=TRUE)
data<-merge(Q,SSC, by.x="Time.stamp",by.y="DATE.TIME",all.x=TRUE)
heaD(data)
head(data)
write.csv(data,file = "C:/Users/lgormansanisaca/Downloads/SSC_Q_merge.csv",row.names = FALSE)
?write.csv
write.csv(data,file = "C:/Users/lgormansanisaca/Downloads/SSC_Q_merge.csv",row.names = FALSE,na="")
##########################
# SPARROW R CONTROL FILE #
##########################
# Authors:  R. Alexander, USGS, Reston, VA (ralex@usgs.gov)
#           L. Gorman-Sanisaca, USGS, Baltimore, MD (lgormansanisaca@usgs.gov)
# Modified: 05-26-2017
# SPARROW URL:  http://water.usgs.gov/nawqa/sparrow/
##############################################
### SPECIFY USER SETTINGS AND LOAD PACKAGE ###
##############################################
#######################################
### 1. SET PATH AND DIRECTORY NAMES ###
#######################################
path_main <- "S:/R_SPARROW/R_SPARROW_master"
#results, data, and gis directories should be in the same folder at the same level
results_directoryName<-"results"
data_directoryName<-"mydata"
gis_directoryName<-"gis"
csv_decimalSeparator <- "."
csv_columnSeparator <- ","
###############################
### 2. Load the R functions ###
###############################
#open Run Instructions
#shell.exec(paste(path_main,"/runInstructions.txt",sep=""))
# Install required packages
#   this is a one time process unless a new version of R is installed
#   packages previously installed by user will be skipped
if_install_packages<-"no"
#run these 3 lines together to install packages
source(paste(path_main,"/R/installPackages.R",sep=""))
installPackages(if_install_packages)
# Load RSPARROW functions (These 2 lines should ALWAYS be run together)
suppressWarnings(remove(list=c("saved","runScript","run2","runRsparrow","runOld")))
devtools::load_all(path_main,recompile = FALSE)
#######################################################################
### 3. SPECIFY OPTIONS FOR NETWORK ATTRIBUTES AND AREA VERIFICATION ###
#######################################################################
#   NOTE: This section is only executed if data import is run
#         to run data import set run_dataImport<-"yes" and load_previousDataImport<-"no"
# Verify drainage area accumlation in the network
#   NOTE: This requires that precalculated values of 'demtarea' are present in DATA1
#         Area totals will be affected by 'frac'
if_verify_demtarea <- "no"
# Request the calculation of selected reach attributes:
#  Identify the attributes for calculation and placement in DATA1
#  Select from following: 'hydseq', 'headflag', and/or 'demtarea'
calculate_reach_attribute_list <- c("hydseq","headflag","demtarea")  # calculate for these variables
calculate_reach_attribute_list <- c("hydseq")  # calculate for these variables
calculate_reach_attribute_list <- NA    # no calculation is requested
# Specify any additional DATA1 variables (and conditions) to be used to filter reaches:
#  Default conditions are FNODE > 0 and TNODE > 0
#  The filter is used to create 'subdata' object from 'data1'
filter_data1_conditions <- c("data1$drainden > 0 & !is.na(data1$drainden)")
filter_data1_conditions <- NA
# Indicate whether hydseq in the DATA1 file needs to be reversed
if_reverse_hydseq <- "no"
#Select input data file (accepted file types ".csv" or binary file  with no extension created in previous RSPARROW run)
#Binary file will be automatically created if file type is not binary for fast import in future runs
input_data_fileName <- "data1.csv"
#Create an initial Data Dictionary file from the data1 column names
#This file will have to be edited prior to executing RSPARROW
create_initial_dataDictionary<-"no"
#Create an initial parameter and design_matrix files from names in the Data Dictionary file
#The parameter names must be listed for both the sparrowNames and data1UserNames and the
#  varType should be defined as SOURCE, DELIVF, STRM, or RESV to populate parmType in the
#  (run_id)_parameters.CSV
#The initial file will have to be edited prior to executing RSPARROW
create_initial_parameterControlFiles<-"no"
#Indicate whether or not to run _userModifyData.R
if_userModifyData<-"yes"
#####################################################
### 4. SPECIFY MONITORING SITE FILTERING CRITERIA ###
#####################################################
# The index 'calsite' requires setting in the modifications function to exclude unwanted sites
# (calsites:  1=site selected for calibration; 0 or NA = site not used)
# Default setting = 1 for sites with positive loads 'depvar>0'
# Minimum drainage area size for monitoring sites located on headwater reaches
minimum_headwater_site_area <- 0
# Minimum number of reaches between monitoring sites
minimum_reaches_separating_sites <- 1
# Minimum allowable incremental drainage area between monitoring sites
minimum_site_incremental_area <- 0
##############################
### 5. ESTIMATION SETTINGS ###
##############################
# Specify if the delivery variables are to be mean adjusted (recommended). This
#  improves the interpretability of the source coefficients and gives meaning to
#  the land-to-water delivery factor. */
if_mean_adjust_delivery_vars <- "yes"
# Specify the SAS IML reach decay function code.
reach_decay_specification <- "exp(-data[,jdecvar[i]] * beta1[,jbdecvar[i]])"
# Specify the SAS IML reservoir decay function code.
#reservoir_decay_specification <- "exp(-data[,jresvar[i]] * beta1[,jbresvar[i]])"
reservoir_decay_specification <- "(1 / (1 + data[,jresvar[i]] * beta1[,jbresvar[i]]))"
# Specify if estimation is to be performed
#  ("no" obtains coefficient estimates from a previous estimation;
#    if no previous estimates available, then the initial coefficient values in the beta file are used)
# "yes" indicates that all prediction, maps, and scenario files
#from the subdirectory with the name = run_id will be deleted
#and only regenerated if settings are turned on
if_estimate <- "yes"
#Specify if simulation is to be performed using the initial parameter values
# "yes" indicates that all prediction, maps, and scenario files
#from the subdirectory with the name = run_id will be deleted
#and only regenerated if settings are turned on
if_estimate_simulation<-"no"
#Specify whether or not to overwrite previous results
if_overwrite<-"yes"
# Specify if more accurate Hessian coefficient SEs are to be estimated
#  Note: set to "no" for initial exploratory models to reduce run times
#  Set to "yes" if the Hessian was previously run and results should be printed in summary table
ifHess <- "yes"
# NLMRT optimization shift setting that tests floating-point equality
# Initially select values between 1.0e+12 and 1.0e+14
# Lower magnitude offset values will execute more NLLS iterations
s_offset <- 1.0e+14
# Select regression weights:  "default" or "area" (area = weights proportional to incremental drainage size)
NLLS_weights <- "default"
# Specify if auto-scaling of parameters for optimization is to be used
# if "yes" then set 'parmScale' in (run_id)_parameters.CSV to 1.0 for fully automated scaling
# (i.e., the scaling value is automatically derived so that the initial value 'parmInit' falls between 1 and 10)
# or allow use of the user-specified 'parmScale' value to scale the initial value
if_auto_scaling <- "no"
##############################
### 6. DIAGNOSTIC SETTINGS ###
##############################
# Specifiy if the spatial autocorrelation diagnostic graphics for Moran's I test are to be output
if_diagnostics <- "no"
# Specify spatially contiguous discrete classification variables (e.g., HUC-x) for producing site diagnostics
# Diagnostics include: (1) observed-predicted plots
#                      (2) spatial autocorrelation (only the first variable is used)
#                      (3) sensitivities (only the first variable is used)
classvar<-NA  # for NA, total drainage area is used as the default classification variable
classvar <- c("huc2","huc4")
# Specify non-contiguous land use classification variables for boxplots of observed-predicted ratios by decile class
#  (land use expressed as a percentage of the incremental area between monitoring sites)
class_landuse<-NA   # for NA, total drainage area is used as the default classification variable
class_landuse <- c("forest","agric","urban","shrubgrass")
class_landuse_percent<-c(90,50,80,10)
# Specify whether correlations among explanatory variables are to be executed using 'corrgroup'
select_corr <- "no"
##############################
### 7. VALIDATION SETTINGS ###
##############################
# Split the monitoring sites into calibration and validation set
if_validate <- "no"
# Indicate the decimal fraction of the monitoring sites as validation sites
pvalidate <- 0.25
##############################
### 8. PREDICTION SETTINGS ###
##############################
# Specify if standard predictions are to be made
#  Note: Bias retransformation correction based on NLLS mean estimate
if_predict <- "yes"
# Specify the concentration conversion factor, computed as Concentration = load / discharge * ConcFactor
ConcFactor <- 3.170979e-05   # kg/yr and m3/s to mg/L
ConcFactor <- 0.001143648    # kg/yr and cfs to mg/L
#Specify additional variables to include in prediction and yield csv files
add_vars<-c("huc2","huc4")
#####################################################
### 9. PREDICTION AND DIAGNOSTIC MAPPING SETTINGS ###
#####################################################
# Load predictions:
#   pload_total                Total load (fully decayed)
#   pload_(sources)            Source load (fully decayed)
#   mpload_total               Monitoring-adjusted total load (fully decayed)
#   mpload_(sources)           Monitoring-adjusted source load (fully decayed)
#   pload_nd_total             Total load delivered to streams (no stream decay)
#   pload_nd_(sources)         Source load delivered to streams (no stream decay)
#   pload_inc                  Total incremental load delivered to streams
#   pload_inc_(sources)        Source incremental load delivered to streams
#   deliv_frac                 Fraction of total load delivered to terminal reach
#   pload_inc_deliv            Total incremental load delivered to terminal reach
#   pload_inc_(sources)_deliv  Source incremental load delivered to terminal reach
#   share_total_(sources)      Source shares for total load (percent)
#   share_inc_(sources)        Source share for incremental load (percent)
# Yield predictions:
#   Concentration              Concentration based on decayed total load and discharge
#   yield_total                Total yield (fully decayed)
#   yield_(sources)            Source yield (fully decayed)
#   myield_total               Monitoring-adjusted total yield (fully decayed)
#   myield_(sources)           Monitoring-adjusted source yield (fully decayed)
#   yield_inc                  Total incremental yield delivered to streams
#   yield_inc_(sources)        Source incremental yield delivered to streams
#   yield_inc_deliv            Total incremental yield delivered to terminal reach
#   yield_inc_(sources)_deliv  Source incremental yield delivered to terminal reach
# Uncertainty predictions (requires prior execution of bootstrap predictions):
#   se_pload_total             Standard error of the total load (percent of mean)
#   ci_pload_total             95% prediction interval of the total load (percent of mean)
# Specify the geographic units minimum/maximum limits for mapping of Residuals and prediction maps
# If set to NA (missing), limits will be automatically determined from the monitoring site values
lat_limit <- c(35,50)
lon_limit <- c(-105,-70)
# Identify list of load and yield predictions for mapping to output PDF file (enter NA for none)
# Any variables listed in the data-dictionary are available for mapping by streams or catchments
# Note: To map model predictions, then 'if_predict' must = "yes" or predictions must have been
#       previouly executed
master_map_list <- c("pload_total","se_pload_total","ci_pload_total",
"deliv_frac","demtarea","hydseq",
"yield_total","yield_inc","share_total_ndep","share_inc_ndep")
master_map_list <- NA
#master_map_list <- c("pload_total","share_total_ndep")
#Trigger interactive Rshiny Maps upon completing run
enable_interactiveMaps<-"yes"
#Identify site attributes to map
map_siteAttributes.list<-c("meanload","meanyield","meanconc","meanloadSE")
#specify breakpoints for mapping of residuals
#if residual_map_breakpoints set to NA, then breakpoint defaults will be applied
#   breakpoint defaults are c(-2.5,-0.75,-0.25,0,0.25,0.75,2.5)
#   breakpoints must have a length of 7 and be centered around 0
residual_map_breakpoints<-c(-2.5,-0.75,-0.25,0,0.25,0.75,2.5)
#specify scaling factor for points on residual and siteAttributes maps
site_mapPointScale<-1
#Identify type of map(s) to output to PDF file from "stream","catchment", or "both"
output_map_type<-c("both")
# Identify the stream reach shape file and 'waterid' common variable in the shape file
lineShapeName <- "ccLinesMRB3"
lineWaterid <- "MRB_ID"
# Identify the stream catchment polygon shape file and 'waterid' common variable in the shape file
polyShapeName <- "mrb3_cats_usonly_withdata_tn"
ployWaterid <- "MRB_ID"
# Identify optional geospatial shape file for overlay of lines on stream/catchment maps
LineShapeGeo <- NA
LineShapeGeo <- "states"
# Identify the desired Coordinate Reference System (CRS) mapping transform for geographic (latitude-longitude)
CRStext <- "+proj=longlat +datum=NAD83"
# Indicate whether shape files are to be converted to binary to reduce execution times
if_create_binary_maps<-"no"
# select files to convert to binary from c("lineShapeName","polyShapeName","LineShapeGeo")
convertShapeToBinary.list <- c("lineShapeName","polyShapeName","LineShapeGeo")
convertShapeToBinary.list <- c("lineShapeName")
########################################
### 10. PREDICTION SCENARIO SETTINGS ###
########################################
# Indicate the spatial domain to apply scenario predictions:  "none", "all reaches", "selected reaches"
#  NOTE: (1) output includes CSV files for the changed absolute values of loads,
#            concentration, and yields and CSV for the changes in all values
#            (expressed as a ratio of new to baseline condition)
#        (2) requires prior or active execution of standard predictions to support baseline comparison
if_predict_scenarios <- "all reaches"
if_predict_scenarios <- "selected reaches"
if_predict_scenarios <- "none"     # do not execute scenarios
#Set scenario name; this becomes the directory and file name for all scenario output
#  NOTE: only one scenario can be run at a time; avoid using "/" or "\" for name
scenario_name<-"scenario1"
# Identify prediction variables to map change from baseline loads, expressed as ratio of new to baseline load
scenario_map_list <- c("pload_total","pload_inc")
# OPTION 1: Settings for application of source reductions to "all reaches":
# Identify source variables for evaluation of downstream effects of source reductions (increases)
scenario_sources <- NA
scenario_sources <- c("point","ndep","FARM_N")
# Source adjustment reduction (or increase) factors to apply to "all reaches"
#  (for example, enter 0.1 or 1.1 for a 10% reduction or increase in sources, respectively)
scenario_all_factors <- NA
scenario_all_factors <- c(0.5,0.25,1.15)
# OPTION 2: Settings for application of source reductions to user-specified "selected reaches":
# (A) Specify the adjustment factors in the 'userModifyData.R' subroutine, such as
#      (e.g., S_point <- ifelse(huc2 == 5,0.5,1)  # point sources are reduced by 0.5 in Ohio Basin)
# (B) Add the variable names for the factors to the 'varnames' data dictionary
#       (e.g, "S_point","S_ndep","S_FARM_N")
##############################
### 11. BOOTSTRAP SETTINGS ###
##############################
# Number of parametric bootstrap iterations
biters <- 5
# Specify the initial seed for the bootstraps
iseed <- 139933493
# Specify if parametric bootstrap estimation (Monte Carlo) is to be done
if_boot_estimate <- "no"
# Specify if bootstrap predictions (mean, SE, confidence intervals) are to be made
#  Note: Bias retransformation correction based on parametric bootstrap estimation
#        Requires completion of bootstrap estimation
if_boot_predict <- "no"
#############################################
### 12. SET OUTPUT/INPUT FILENAMES PREFIX ###
#############################################
#Select current run_id for the model
run_id<-"TN_rev1"
#Specify name of old model to copy into results directory for edit and run
#Set copy_PriorModelFiles<-NA to run current control files located in results directory
copy_PriorModelFiles<-NA
#Select models to compare, use ONLY previous run_ids found in the results directory; select NA for no comparision
compare_models<-c("TN_rev1")
#compare_models<-NA
#Specify model comparison name, subdirectory name for the comparision results
modelComparison_name<-"Compare1"
# modelComparison_name<-NA
# Option to open CSV files from R-session for editing
edit_Parameters<-"no"
edit_DesignMatrix<-"no"
edit_dataDictionary<-"no"
batch_mode<-"no"
run_dataImport<-"yes" # Initially required to read Sparrow input files,
#   (data1, data dictionary) and will include any user-requested
#   updates to network attributes (hydseq, headflag, demtarea).
# Resulting objects are stored as binary file "(input_data_fileName)_priorImport"
#   in the results directory.
# Set to "no" for subsequent runs and set load_previousDataImport = "yes"
# Re-run if revisions are made to the data1 and/or data dictionary.
# load_previousDataImport<- 'no' MUST be set to re-run data import
load_previousDataImport<-"no"  # Loads previous binary data input file "(input_data_fileName)_priorImport"
#  from results directory. This setting will override run_dataImport.
# NOTE: Section 3 : SPECIFY OPTIONS FOR NETWORK ATTRIBUTES AND AREA VERIFICATION
#     will ONLY be executed if load_previousDataImport<-"no"
#     and run_dataImport<-"yes"
#############################################
## Start Model Run
## DO NOT MAKE EDITS TO THIS SECTION
#############################################
activeFile<-findScriptName() #get activeFile Name
runRsparrow<-"yes"
rstudioapi::setCursorPosition(c(1,1,417,1))
source(paste(path_main,"/R/runRsparrow.R",sep=""))
?replaceNAs
?replaceNAs
?SPARROW
vignette(path_main)
vignette("SPARROW")
vignette("RSPARROW")
vignette("RSPARROW_vignette",package="SPARROW")
setwd(path_main)
vignette("RSPARROW_vignette",package="SPARROW")
?vignette
vignette("RSPARROW_vignette")
vignette("RSPARROW_vignette",lib.loc=path_main)
browseVignettes("RSPARROW_vignette")
browseVignettes("SPARROW")
browseVignettes(path_main)
setwd("S:/R_SPARROW/R_SPARROW_master")
path_main<-getwd()
suppressWarnings(remove(list=c("saved","runScript","run2","runRsparrow","runOld")))
devtools::load_all(path_main,recompile = FALSE)
library(roxygen2)
roxygen2::roxygenise()
browseVignettes("SPARROW")
?devtools::build_vignettes
devtools::build_vignettes()
browseVignettes("SPARROW")
vignette("RSPARROW_vignette","SPARROW")
